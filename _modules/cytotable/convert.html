
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>cytotable.convert &#8212; CytoTable v0.0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="https://unpkg.com/mermaid@10.2.0/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for cytotable.convert</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">CytoTable: convert - transforming data for use with pyctyominer.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">uuid</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">cast</span>

<span class="kn">import</span> <span class="nn">parsl</span>
<span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>
<span class="kn">from</span> <span class="nn">parsl.app.app</span> <span class="kn">import</span> <span class="n">join_app</span><span class="p">,</span> <span class="n">python_app</span>

<span class="kn">from</span> <span class="nn">cytotable.exceptions</span> <span class="kn">import</span> <span class="n">CytoTableException</span>
<span class="kn">from</span> <span class="nn">cytotable.presets</span> <span class="kn">import</span> <span class="n">config</span>
<span class="kn">from</span> <span class="nn">cytotable.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_column_sort</span><span class="p">,</span>
    <span class="n">_default_parsl_config</span><span class="p">,</span>
    <span class="n">_expand_path</span><span class="p">,</span>
    <span class="n">_parsl_loaded</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="nd">@python_app</span>
<span class="k">def</span> <span class="nf">_get_table_columns_and_types</span><span class="p">(</span><span class="n">source</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Gather column data from table through duckdb.</span>

<span class="sd">    Args:</span>
<span class="sd">        source: Dict[str, Any]</span>
<span class="sd">            Contains the source data to be chunked. Represents a single</span>
<span class="sd">            file or table of some kind.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[Dict[str, str]]</span>
<span class="sd">            list of dictionaries which each include column level information</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">import</span> <span class="nn">pathlib</span>

    <span class="kn">import</span> <span class="nn">duckdb</span>

    <span class="kn">from</span> <span class="nn">cytotable.utils</span> <span class="kn">import</span> <span class="n">_duckdb_reader</span><span class="p">,</span> <span class="n">_sqlite_mixed_type_query_to_parquet</span>

    <span class="n">source_path</span> <span class="o">=</span> <span class="n">source</span><span class="p">[</span><span class="s2">&quot;source_path&quot;</span><span class="p">]</span>
    <span class="n">source_type</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">source_path</span><span class="p">)</span><span class="o">.</span><span class="n">suffix</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

    <span class="c1"># prepare the data source in the form of a duckdb query</span>
    <span class="n">select_source</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;read_csv_auto(&#39;</span><span class="si">{</span><span class="n">source_path</span><span class="si">}</span><span class="s2">&#39;)&quot;</span>
        <span class="k">if</span> <span class="n">source_type</span> <span class="o">==</span> <span class="s2">&quot;.csv&quot;</span>
        <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;sqlite_scan(&#39;</span><span class="si">{</span><span class="n">source_path</span><span class="si">}</span><span class="s2">&#39;, &#39;</span><span class="si">{</span><span class="n">source</span><span class="p">[</span><span class="s1">&#39;table_name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39;)&quot;</span>
    <span class="p">)</span>

    <span class="c1"># Query top 5 results from table and use pragma_storage_info() to</span>
    <span class="c1"># gather duckdb interpreted data typing. We gather 5 values for</span>
    <span class="c1"># each column to help with type inferences (where smaller sets</span>
    <span class="c1"># may yield lower data type accuracy for the full table).</span>
    <span class="n">select_query</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        /* we create an in-mem table for later use with the pragma_storage_info call</span>
<span class="s2">        as this call only functions with materialized tables and not views or related */</span>
<span class="s2">        CREATE TABLE column_details AS</span>
<span class="s2">            (SELECT *</span>
<span class="s2">            FROM &amp;select_source</span>
<span class="s2">            LIMIT 5</span>
<span class="s2">            );</span>

<span class="s2">        /* selects specific column metadata from pragma_storage_info */</span>
<span class="s2">        SELECT DISTINCT</span>
<span class="s2">            column_id,</span>
<span class="s2">            column_name,</span>
<span class="s2">            segment_type as column_dtype</span>
<span class="s2">        FROM pragma_storage_info(&#39;column_details&#39;)</span>
<span class="s2">        /* avoid duplicate entries in the form of VALIDITY segment_types */</span>
<span class="s2">        WHERE segment_type != &#39;VALIDITY&#39;</span>
<span class="s2">        /* explicitly order the columns by their id to avoid inconsistent results */</span>
<span class="s2">        ORDER BY column_id ASC;</span>
<span class="s2">        &quot;&quot;&quot;</span>

    <span class="c1"># attempt to read the data to parquet from duckdb</span>
    <span class="c1"># with exception handling to read mixed-type data</span>
    <span class="c1"># using sqlite3 and special utility function</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># isolate using new connection to read data with chunk size + offset</span>
        <span class="c1"># and export directly to parquet via duckdb (avoiding need to return data to python)</span>
        <span class="c1"># perform the query and create a list of dictionaries with the column data for table</span>
        <span class="k">with</span> <span class="n">_duckdb_reader</span><span class="p">()</span> <span class="k">as</span> <span class="n">ddb_reader</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="n">ddb_reader</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
                    <span class="n">select_query</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&amp;select_source&quot;</span><span class="p">,</span> <span class="n">select_source</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="o">.</span><span class="n">arrow</span><span class="p">()</span>
                <span class="o">.</span><span class="n">to_pylist</span><span class="p">()</span>
            <span class="p">)</span>

    <span class="k">except</span> <span class="n">duckdb</span><span class="o">.</span><span class="n">Error</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="c1"># if we see a mismatched type error</span>
        <span class="c1"># run a more nuanced query through sqlite</span>
        <span class="c1"># to handle the mixed types</span>
        <span class="k">if</span> <span class="s2">&quot;Mismatch Type Error&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span> <span class="ow">and</span> <span class="n">source_type</span> <span class="o">==</span> <span class="s2">&quot;.sqlite&quot;</span><span class="p">:</span>
            <span class="n">arrow_data_tbl</span> <span class="o">=</span> <span class="n">_sqlite_mixed_type_query_to_parquet</span><span class="p">(</span>
                <span class="n">source_path</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="s2">&quot;source_path&quot;</span><span class="p">]),</span>
                <span class="n">table_name</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="s2">&quot;table_name&quot;</span><span class="p">]),</span>
                <span class="c1"># chunk size is set to 5 as a limit similar</span>
                <span class="c1"># to above SQL within select_query variable</span>
                <span class="n">chunk_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                <span class="c1"># offset is set to 0 start at first row</span>
                <span class="c1"># result from table</span>
                <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">with</span> <span class="n">_duckdb_reader</span><span class="p">()</span> <span class="k">as</span> <span class="n">ddb_reader</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span>
                    <span class="n">ddb_reader</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
                        <span class="n">select_query</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&amp;select_source&quot;</span><span class="p">,</span> <span class="s2">&quot;arrow_data_tbl&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="o">.</span><span class="n">arrow</span><span class="p">()</span>
                    <span class="o">.</span><span class="n">to_pylist</span><span class="p">()</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span>


<span class="nd">@python_app</span>
<span class="k">def</span> <span class="nf">_prep_cast_column_data_types</span><span class="p">(</span>
    <span class="n">columns</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span> <span class="n">data_type_cast_map</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Cast data types per what is received in cast_map.</span>

<span class="sd">    Example:</span>
<span class="sd">    - columns: [{&quot;column_id&quot;:0, &quot;column_name&quot;:&quot;colname&quot;, &quot;column_dtype&quot;:&quot;DOUBLE&quot;}]</span>
<span class="sd">    - data_type_cast_map: {&quot;float&quot;: &quot;float32&quot;}</span>

<span class="sd">    The above passed through this function will set the &quot;column_dtype&quot; value</span>
<span class="sd">    to a &quot;REAL&quot; dtype (&quot;REAL&quot; in duckdb is roughly equivalent to &quot;float32&quot;)</span>

<span class="sd">    Args:</span>
<span class="sd">        table_path: str:</span>
<span class="sd">            Path to a parquet file which will be modified.</span>
<span class="sd">        data_type_cast_map: Dict[str, str]</span>
<span class="sd">            A dictionary mapping data type groups to specific types.</span>
<span class="sd">            Roughly to eventually align with DuckDB types:</span>
<span class="sd">            https://duckdb.org/docs/sql/data_types/overview</span>

<span class="sd">            Note: includes synonym matching for common naming convention</span>
<span class="sd">            use in Pandas and/or PyArrow via cytotable.utils.DATA_TYPE_SYNONYMS</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[Dict[str, str]]</span>
<span class="sd">            list of dictionaries which each include column level information</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

    <span class="kn">from</span> <span class="nn">cytotable.utils</span> <span class="kn">import</span> <span class="n">_arrow_type_cast_if_specified</span>

    <span class="k">if</span> <span class="n">data_type_cast_map</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span>
            <span class="c1"># map across all columns</span>
            <span class="nb">map</span><span class="p">(</span>
                <span class="n">partial</span><span class="p">(</span>
                    <span class="c1"># attempts to cast the columns provided</span>
                    <span class="n">_arrow_type_cast_if_specified</span><span class="p">,</span>
                    <span class="c1"># set static data_type_case_map arg for</span>
                    <span class="c1"># use with all fields</span>
                    <span class="n">data_type_cast_map</span><span class="o">=</span><span class="n">data_type_cast_map</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">columns</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">columns</span>


<span class="nd">@python_app</span>
<span class="k">def</span> <span class="nf">_get_table_chunk_offsets</span><span class="p">(</span>
    <span class="n">chunk_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">source</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sql_stmt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get table data chunk offsets for later use in capturing segments</span>
<span class="sd">    of values. This work also provides a chance to catch problematic</span>
<span class="sd">    input data which will be ignored with warnings.</span>

<span class="sd">    Args:</span>
<span class="sd">        source: Dict[str, Any]</span>
<span class="sd">            Contains the source data to be chunked. Represents a single</span>
<span class="sd">            file or table of some kind.</span>
<span class="sd">        chunk_size: int</span>
<span class="sd">            The size in rowcount of the chunks to create.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[int]</span>
<span class="sd">            List of integers which represent offsets to use for reading</span>
<span class="sd">            the data later on.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">import</span> <span class="nn">logging</span>
    <span class="kn">import</span> <span class="nn">pathlib</span>

    <span class="kn">import</span> <span class="nn">duckdb</span>
    <span class="kn">from</span> <span class="nn">cloudpathlib</span> <span class="kn">import</span> <span class="n">AnyPath</span>

    <span class="kn">from</span> <span class="nn">cytotable.exceptions</span> <span class="kn">import</span> <span class="n">NoInputDataException</span>
    <span class="kn">from</span> <span class="nn">cytotable.utils</span> <span class="kn">import</span> <span class="n">_duckdb_reader</span>

    <span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">source</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">table_name</span> <span class="o">=</span> <span class="n">source</span><span class="p">[</span><span class="s2">&quot;table_name&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;table_name&quot;</span> <span class="ow">in</span> <span class="n">source</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">source_path</span> <span class="o">=</span> <span class="n">source</span><span class="p">[</span><span class="s2">&quot;source_path&quot;</span><span class="p">]</span>
        <span class="n">source_type</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">source_path</span><span class="p">)</span><span class="o">.</span><span class="n">suffix</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># for csv&#39;s, check that we have more than one row (a header and data values)</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">source_type</span> <span class="o">==</span> <span class="s2">&quot;.csv&quot;</span>
                <span class="ow">and</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">AnyPath</span><span class="p">(</span><span class="n">source_path</span><span class="p">)</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;r&quot;</span><span class="p">))</span> <span class="o">&lt;=</span> <span class="mi">1</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="n">NoInputDataException</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Data file has 0 rows of values. Error in file: </span><span class="si">{</span><span class="n">source_path</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="c1"># gather the total rowcount from csv or sqlite data input sources</span>
            <span class="k">with</span> <span class="n">_duckdb_reader</span><span class="p">()</span> <span class="k">as</span> <span class="n">ddb_reader</span><span class="p">:</span>
                <span class="n">rowcount</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
                    <span class="n">ddb_reader</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
                        <span class="c1"># nosec</span>
                        <span class="sa">f</span><span class="s2">&quot;SELECT COUNT(*) from read_csv_auto(&#39;</span><span class="si">{</span><span class="n">source_path</span><span class="si">}</span><span class="s2">&#39;, header=TRUE, delim=&#39;,&#39;)&quot;</span>
                        <span class="k">if</span> <span class="n">source_type</span> <span class="o">==</span> <span class="s2">&quot;.csv&quot;</span>
                        <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;SELECT COUNT(*) from sqlite_scan(&#39;</span><span class="si">{</span><span class="n">source_path</span><span class="si">}</span><span class="s2">&#39;, &#39;</span><span class="si">{</span><span class="n">table_name</span><span class="si">}</span><span class="s2">&#39;)&quot;</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">fetchone</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">)</span>

        <span class="c1"># catch input errors which will result in skipped files</span>
        <span class="k">except</span> <span class="p">(</span>
            <span class="n">duckdb</span><span class="o">.</span><span class="n">InvalidInputException</span><span class="p">,</span>
            <span class="n">NoInputDataException</span><span class="p">,</span>
        <span class="p">)</span> <span class="k">as</span> <span class="n">invalid_input_exc</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="n">msg</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Skipping file due to input file errors: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">invalid_input_exc</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

            <span class="k">return</span> <span class="kc">None</span>

    <span class="c1"># find chunk offsets from sql statement</span>
    <span class="k">elif</span> <span class="n">sql_stmt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># gather the total rowcount from csv or sqlite data input sources</span>
        <span class="k">with</span> <span class="n">_duckdb_reader</span><span class="p">()</span> <span class="k">as</span> <span class="n">ddb_reader</span><span class="p">:</span>
            <span class="n">rowcount</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
                <span class="n">ddb_reader</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
                    <span class="c1"># nosec</span>
                    <span class="sa">f</span><span class="s2">&quot;SELECT COUNT(*) FROM (</span><span class="si">{</span><span class="n">sql_stmt</span><span class="si">}</span><span class="s2">)&quot;</span>
                <span class="p">)</span><span class="o">.</span><span class="n">fetchone</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="p">)</span>

    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span>
        <span class="nb">range</span><span class="p">(</span>
            <span class="mi">0</span><span class="p">,</span>
            <span class="c1"># gather rowcount from table and use as maximum for range</span>
            <span class="n">rowcount</span><span class="p">,</span>
            <span class="c1"># step through using chunk size</span>
            <span class="n">chunk_size</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>


<span class="nd">@python_app</span>
<span class="k">def</span> <span class="nf">_source_chunk_to_parquet</span><span class="p">(</span>
    <span class="n">source_group_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">source</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="n">chunk_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">dest_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Export source data to chunked parquet file using chunk size and offsets.</span>

<span class="sd">    Args:</span>
<span class="sd">        source_group_name: str</span>
<span class="sd">            Name of the source group (for ex. compartment or metadata table name).</span>
<span class="sd">        source: Dict[str, Any]</span>
<span class="sd">            Contains the source data to be chunked. Represents a single</span>
<span class="sd">            file or table of some kind along with collected information about table.</span>
<span class="sd">        chunk_size: int</span>
<span class="sd">            Row count to use for chunked output.</span>
<span class="sd">        offset: int</span>
<span class="sd">            The offset for chunking the data from source.</span>
<span class="sd">        dest_path: str</span>
<span class="sd">            Path to store the output data.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str</span>
<span class="sd">            A string of the output filepath.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">import</span> <span class="nn">pathlib</span>

    <span class="kn">import</span> <span class="nn">duckdb</span>
    <span class="kn">from</span> <span class="nn">cloudpathlib</span> <span class="kn">import</span> <span class="n">AnyPath</span>
    <span class="kn">from</span> <span class="nn">pyarrow</span> <span class="kn">import</span> <span class="n">parquet</span>

    <span class="kn">from</span> <span class="nn">cytotable.utils</span> <span class="kn">import</span> <span class="p">(</span>
        <span class="n">_duckdb_reader</span><span class="p">,</span>
        <span class="n">_sqlite_mixed_type_query_to_parquet</span><span class="p">,</span>
        <span class="n">_write_parquet_table_with_metadata</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># attempt to build dest_path</span>
    <span class="n">source_dest_path</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dest_path</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">source_group_name</span><span class="p">)</span><span class="o">.</span><span class="n">stem</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="si">}</span><span class="s2">/&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="s1">&#39;source_path&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">name</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">source_dest_path</span><span class="p">)</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># build the column selection block of query</span>
    <span class="n">select_columns</span> <span class="o">=</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="c1"># here we cast the column to the specified type ensure the colname remains the same</span>
            <span class="sa">f</span><span class="s2">&quot;CAST(</span><span class="se">\&quot;</span><span class="si">{</span><span class="n">column</span><span class="p">[</span><span class="s1">&#39;column_name&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\&quot;</span><span class="s2"> AS </span><span class="si">{</span><span class="n">column</span><span class="p">[</span><span class="s1">&#39;column_dtype&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">) AS </span><span class="se">\&quot;</span><span class="si">{</span><span class="n">column</span><span class="p">[</span><span class="s1">&#39;column_name&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\&quot;</span><span class="s2">&quot;</span>
            <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">source</span><span class="p">[</span><span class="s2">&quot;columns&quot;</span><span class="p">]</span>
        <span class="p">]</span>
    <span class="p">)</span>

    <span class="c1"># build output query and filepath base</span>
    <span class="c1"># (chunked output will append offset to keep output paths unique)</span>
    <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">AnyPath</span><span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="s2">&quot;source_path&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">suffix</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;.csv&quot;</span><span class="p">:</span>
        <span class="n">base_query</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;SELECT </span><span class="si">{</span><span class="n">select_columns</span><span class="si">}</span><span class="s2"> FROM read_csv_auto(&#39;</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="s1">&#39;source_path&#39;</span><span class="p">])</span><span class="si">}</span><span class="s2">&#39;, header=TRUE, delim=&#39;,&#39;)&quot;</span>
        <span class="n">result_filepath_base</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">source_dest_path</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="s1">&#39;source_path&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">stem</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="k">elif</span> <span class="nb">str</span><span class="p">(</span><span class="n">AnyPath</span><span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="s2">&quot;source_path&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">suffix</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;.sqlite&quot;</span><span class="p">:</span>
        <span class="n">base_query</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;SELECT </span><span class="si">{</span><span class="n">select_columns</span><span class="si">}</span><span class="s2"> FROM sqlite_scan(&#39;</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="s1">&#39;source_path&#39;</span><span class="p">])</span><span class="si">}</span><span class="s2">&#39;, &#39;</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="s1">&#39;table_name&#39;</span><span class="p">])</span><span class="si">}</span><span class="s2">&#39;)&quot;</span>
        <span class="n">result_filepath_base</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">source_dest_path</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="s1">&#39;source_path&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">stem</span><span class="p">)</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">source</span><span class="p">[</span><span class="s1">&#39;table_name&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="n">result_filepath</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">result_filepath_base</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">offset</span><span class="si">}</span><span class="s2">.parquet&quot;</span>

    <span class="c1"># Attempt to read the data to parquet file</span>
    <span class="c1"># using duckdb for extraction and pyarrow for</span>
    <span class="c1"># writing data to a parquet file.</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># read data with chunk size + offset</span>
        <span class="c1"># and export to parquet</span>
        <span class="k">with</span> <span class="n">_duckdb_reader</span><span class="p">()</span> <span class="k">as</span> <span class="n">ddb_reader</span><span class="p">:</span>
            <span class="n">_write_parquet_table_with_metadata</span><span class="p">(</span>
                <span class="n">table</span><span class="o">=</span><span class="n">ddb_reader</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                    </span><span class="si">{</span><span class="n">base_query</span><span class="si">}</span>
<span class="s2">                    LIMIT </span><span class="si">{</span><span class="n">chunk_size</span><span class="si">}</span><span class="s2"> OFFSET </span><span class="si">{</span><span class="n">offset</span><span class="si">}</span>
<span class="s2">                    &quot;&quot;&quot;</span>
                <span class="p">)</span><span class="o">.</span><span class="n">arrow</span><span class="p">(),</span>
                <span class="n">where</span><span class="o">=</span><span class="n">result_filepath</span><span class="p">,</span>
            <span class="p">)</span>
    <span class="c1"># Include exception handling to read mixed-type data</span>
    <span class="c1"># using sqlite3 and special utility function.</span>
    <span class="k">except</span> <span class="n">duckdb</span><span class="o">.</span><span class="n">Error</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="c1"># if we see a mismatched type error</span>
        <span class="c1"># run a more nuanced query through sqlite</span>
        <span class="c1"># to handle the mixed types</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="s2">&quot;Mismatch Type Error&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">str</span><span class="p">(</span><span class="n">AnyPath</span><span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="s2">&quot;source_path&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">suffix</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;.sqlite&quot;</span>
        <span class="p">):</span>
            <span class="n">_write_parquet_table_with_metadata</span><span class="p">(</span>
                <span class="c1"># here we use sqlite instead of duckdb to extract</span>
                <span class="c1"># data for special cases where column and value types</span>
                <span class="c1"># may not align (which is valid functionality in SQLite).</span>
                <span class="n">table</span><span class="o">=</span><span class="n">_sqlite_mixed_type_query_to_parquet</span><span class="p">(</span>
                    <span class="n">source_path</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="s2">&quot;source_path&quot;</span><span class="p">]),</span>
                    <span class="n">table_name</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="s2">&quot;table_name&quot;</span><span class="p">]),</span>
                    <span class="n">chunk_size</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">,</span>
                    <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">where</span><span class="o">=</span><span class="n">result_filepath</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span>

    <span class="c1"># return the filepath for the chunked output file</span>
    <span class="k">return</span> <span class="n">result_filepath</span>


<span class="nd">@python_app</span>
<span class="k">def</span> <span class="nf">_prepend_column_name</span><span class="p">(</span>
    <span class="n">table_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">source_group_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">identifying_columns</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">metadata</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]],</span>
    <span class="n">compartments</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Rename columns using the source group name, avoiding identifying columns.</span>

<span class="sd">    Notes:</span>
<span class="sd">    * A source_group_name represents a filename referenced as part of what</span>
<span class="sd">    is specified within targets.</span>

<span class="sd">    Args:</span>
<span class="sd">        table_path: str:</span>
<span class="sd">            Path to a parquet file which will be modified.</span>
<span class="sd">        source_group_name: str:</span>
<span class="sd">            Name of data source source group (for common compartments, etc).</span>
<span class="sd">        identifying_columns: List[str]:</span>
<span class="sd">            Column names which are used as ID&#39;s and as a result need to be</span>
<span class="sd">            treated differently when renaming.</span>
<span class="sd">        metadata: Union[List[str], Tuple[str, ...]]:</span>
<span class="sd">            List of source data names which are used as metadata.</span>
<span class="sd">        compartments: List[str]:</span>
<span class="sd">            List of source data names which are used as compartments.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str</span>
<span class="sd">            Path to the modified file.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">import</span> <span class="nn">logging</span>
    <span class="kn">import</span> <span class="nn">pathlib</span>

    <span class="kn">import</span> <span class="nn">pyarrow.parquet</span> <span class="k">as</span> <span class="nn">parquet</span>

    <span class="kn">from</span> <span class="nn">cytotable.constants</span> <span class="kn">import</span> <span class="n">CYTOTABLE_ARROW_USE_MEMORY_MAPPING</span>
    <span class="kn">from</span> <span class="nn">cytotable.utils</span> <span class="kn">import</span> <span class="n">_write_parquet_table_with_metadata</span>

    <span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

    <span class="n">targets</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">metadata</span><span class="p">)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">compartments</span><span class="p">)</span>

    <span class="c1"># if we have no targets or metadata to work from, return the table unchanged</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="n">msg</span><span class="o">=</span><span class="p">(</span>
                <span class="s2">&quot;Skipping column name prepend operations&quot;</span>
                <span class="s2">&quot;because no compartments or metadata were provided.&quot;</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">table_path</span>

    <span class="n">table</span> <span class="o">=</span> <span class="n">parquet</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span>
        <span class="n">source</span><span class="o">=</span><span class="n">table_path</span><span class="p">,</span> <span class="n">memory_map</span><span class="o">=</span><span class="n">CYTOTABLE_ARROW_USE_MEMORY_MAPPING</span>
    <span class="p">)</span>

    <span class="c1"># stem of source group name</span>
    <span class="c1"># for example:</span>
    <span class="c1">#   targets: [&#39;cytoplasm&#39;]</span>
    <span class="c1">#   source_group_name: &#39;Per_Cytoplasm.sqlite&#39;</span>
    <span class="c1">#   source_group_name_stem: &#39;Cytoplasm&#39;</span>
    <span class="n">source_group_name_stem</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span>
        <span class="c1"># return first result from generator below as index to targets</span>
        <span class="nb">next</span><span class="p">(</span>
            <span class="n">i</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
            <span class="c1"># compare if value from targets in source_group_name stem</span>
            <span class="k">if</span> <span class="n">val</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">source_group_name</span><span class="p">)</span><span class="o">.</span><span class="n">stem</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="c1"># capitalize the result</span>
    <span class="p">]</span><span class="o">.</span><span class="n">capitalize</span><span class="p">()</span>

    <span class="c1"># capture updated column names as new variable</span>
    <span class="n">updated_column_names</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">column_name</span> <span class="ow">in</span> <span class="n">table</span><span class="o">.</span><span class="n">column_names</span><span class="p">:</span>
        <span class="c1"># if-condition for prepending source_group_name_stem to column name</span>
        <span class="c1"># where colname is not in identifying_columns parameter values</span>
        <span class="c1"># and where the column is not already prepended with source_group_name_stem</span>
        <span class="c1"># for example:</span>
        <span class="c1">#   source_group_name_stem: &#39;Cells&#39;</span>
        <span class="c1">#   column_name: &#39;AreaShape_Area&#39;</span>
        <span class="c1">#   updated_column_name: &#39;Cells_AreaShape_Area&#39;</span>
        <span class="k">if</span> <span class="n">column_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">identifying_columns</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">column_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span>
            <span class="n">source_group_name_stem</span><span class="o">.</span><span class="n">capitalize</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="n">updated_column_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">source_group_name_stem</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">column_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># if-condition for prepending &#39;Metadata_&#39; to column name</span>
        <span class="c1"># where colname is in identifying_columns parameter values</span>
        <span class="c1"># and where the column is already prepended with source_group_name_stem</span>
        <span class="c1"># for example:</span>
        <span class="c1">#   source_group_name_stem: &#39;Cells&#39;</span>
        <span class="c1">#   column_name: &#39;Cells_Number_Object_Number&#39;</span>
        <span class="c1">#   updated_column_name: &#39;Metadata_Cells_Number_Object_Number&#39;</span>
        <span class="k">elif</span> <span class="n">column_name</span> <span class="ow">in</span> <span class="n">identifying_columns</span> <span class="ow">and</span> <span class="n">column_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span>
            <span class="n">source_group_name_stem</span><span class="o">.</span><span class="n">capitalize</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="n">updated_column_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Metadata_</span><span class="si">{</span><span class="n">column_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># if-condition for prepending &#39;Metadata&#39; and source_group_name_stem to column name</span>
        <span class="c1"># where colname is in identifying_columns parameter values</span>
        <span class="c1"># and where the colname does not already start with &#39;Metadata_&#39;</span>
        <span class="c1"># and colname not in metadata list</span>
        <span class="c1"># and colname does not include &#39;ObjectNumber&#39; or &#39;TableNumber&#39;</span>
        <span class="c1"># (which are specially treated column names in this context)</span>
        <span class="c1"># for example:</span>
        <span class="c1">#   source_group_name_stem: &#39;Cells&#39;</span>
        <span class="c1">#   column_name: &#39;Parent_Nuclei&#39;</span>
        <span class="c1">#   updated_column_name: &#39;Metadata_Cells_Parent_Nuclei&#39;</span>
        <span class="k">elif</span> <span class="p">(</span>
            <span class="n">column_name</span> <span class="ow">in</span> <span class="n">identifying_columns</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="n">column_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;Metadata_&quot;</span><span class="p">)</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">capitalize</span><span class="p">()</span> <span class="ow">in</span> <span class="n">column_name</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">metadata</span><span class="p">)</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">item</span> <span class="ow">in</span> <span class="n">column_name</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;ObjectNumber&quot;</span><span class="p">,</span> <span class="s2">&quot;TableNumber&quot;</span><span class="p">])</span>
        <span class="p">):</span>
            <span class="n">updated_column_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Metadata_</span><span class="si">{</span><span class="n">source_group_name_stem</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">column_name</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="c1"># if-condition for prepending &#39;Metadata&#39; to column name</span>
        <span class="c1"># where colname doesn&#39;t already start with &#39;Metadata_&#39;</span>
        <span class="c1"># and colname is in identifying_columns parameter values</span>
        <span class="c1"># for example:</span>
        <span class="c1">#   column_name: &#39;ObjectNumber&#39;</span>
        <span class="c1">#   updated_column_name: &#39;Metadata_ObjectNumber&#39;</span>
        <span class="k">elif</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">column_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;Metadata_&quot;</span><span class="p">)</span>
            <span class="ow">and</span> <span class="n">column_name</span> <span class="ow">in</span> <span class="n">identifying_columns</span>
        <span class="p">):</span>
            <span class="n">updated_column_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Metadata_</span><span class="si">{</span><span class="n">column_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># else we add the existing colname to the updated list as-is</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">updated_column_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">column_name</span><span class="p">)</span>

    <span class="c1"># perform table column name updates</span>
    <span class="n">_write_parquet_table_with_metadata</span><span class="p">(</span>
        <span class="n">table</span><span class="o">=</span><span class="n">table</span><span class="o">.</span><span class="n">rename_columns</span><span class="p">(</span><span class="n">updated_column_names</span><span class="p">),</span> <span class="n">where</span><span class="o">=</span><span class="n">table_path</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">table_path</span>


<span class="nd">@python_app</span>
<span class="k">def</span> <span class="nf">_concat_source_group</span><span class="p">(</span>
    <span class="n">source_group_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">source_group</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">dest_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">common_schema</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Concatenate group of source data together as single file.</span>

<span class="sd">    For a reference to data concatenation within Arrow see the following:</span>
<span class="sd">    https://arrow.apache.org/docs/python/generated/pyarrow.concat_tables.html</span>

<span class="sd">    Notes: this function presumes a multi-directory, multi-file common data</span>
<span class="sd">    structure for compartments and other data. For example:</span>

<span class="sd">    Source (file tree):</span>

<span class="sd">    .. code-block:: bash</span>

<span class="sd">        root</span>
<span class="sd">        ├── subdir_1</span>
<span class="sd">        │  └── Cells.csv</span>
<span class="sd">        └── subdir_2</span>
<span class="sd">            └── Cells.csv</span>


<span class="sd">    Becomes:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        # earlier data read into parquet chunks from multiple</span>
<span class="sd">        # data source files.</span>
<span class="sd">        read_data = [</span>
<span class="sd">            {&quot;table&quot;: [&quot;cells-1.parquet&quot;, &quot;cells-2.parquet&quot;]},</span>
<span class="sd">            {&quot;table&quot;: [&quot;cells-1.parquet&quot;, &quot;cells-2.parquet&quot;]},</span>
<span class="sd">        ]</span>

<span class="sd">        # focus of this function</span>
<span class="sd">        concatted = [{&quot;table&quot;: [&quot;cells.parquet&quot;]}]</span>


<span class="sd">    Args:</span>
<span class="sd">        source_group_name: str</span>
<span class="sd">            Name of data source source group (for common compartments, etc).</span>
<span class="sd">        source_group: List[Dict[str, Any]]:</span>
<span class="sd">            Data structure containing grouped data for concatenation.</span>
<span class="sd">        dest_path: Optional[str] (Default value = None)</span>
<span class="sd">            Optional destination path for concatenated sources.</span>
<span class="sd">        common_schema: List[Tuple[str, str]] (Default value = None)</span>
<span class="sd">            Common schema to use for concatenation amongst arrow tables</span>
<span class="sd">            which may have slightly different but compatible schema.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[Dict[str, Any]]</span>
<span class="sd">            Updated dictionary containing concatenated sources.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">import</span> <span class="nn">errno</span>
    <span class="kn">import</span> <span class="nn">pathlib</span>

    <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>
    <span class="kn">import</span> <span class="nn">pyarrow.parquet</span> <span class="k">as</span> <span class="nn">parquet</span>

    <span class="kn">from</span> <span class="nn">cytotable.constants</span> <span class="kn">import</span> <span class="p">(</span>
        <span class="n">CYTOTABLE_ARROW_USE_MEMORY_MAPPING</span><span class="p">,</span>
        <span class="n">CYTOTABLE_DEFAULT_PARQUET_METADATA</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="kn">from</span> <span class="nn">cytotable.exceptions</span> <span class="kn">import</span> <span class="n">SchemaException</span>
    <span class="kn">from</span> <span class="nn">cytotable.utils</span> <span class="kn">import</span> <span class="n">_write_parquet_table_with_metadata</span>

    <span class="c1"># build a result placeholder</span>
    <span class="n">concatted</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="c1"># source path becomes parent&#39;s parent dir with the same filename</span>
            <span class="s2">&quot;source_path&quot;</span><span class="p">:</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">source_group</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;source_path&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">parent</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;/</span><span class="si">{</span><span class="n">source_group</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;source_path&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">stem</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="p">}</span>
    <span class="p">]</span>

    <span class="c1"># build destination path for file to land</span>
    <span class="n">destination_path</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span>
        <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dest_path</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">source_group_name</span><span class="p">)</span><span class="o">.</span><span class="n">stem</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="si">}</span><span class="s2">/&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">source_group_name</span><span class="p">)</span><span class="o">.</span><span class="n">stem</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="si">}</span><span class="s2">.parquet&quot;</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># if there&#39;s already a file remove it</span>
    <span class="n">destination_path</span><span class="o">.</span><span class="n">unlink</span><span class="p">(</span><span class="n">missing_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># ensure the parent directories exist:</span>
    <span class="n">destination_path</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># build the schema for concatenation writer</span>
    <span class="n">writer_schema</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">common_schema</span><span class="p">)</span><span class="o">.</span><span class="n">with_metadata</span><span class="p">(</span>
        <span class="n">CYTOTABLE_DEFAULT_PARQUET_METADATA</span>
    <span class="p">)</span>

    <span class="c1"># build a parquet file writer which will be used to append files</span>
    <span class="c1"># as a single concatted parquet file, referencing the first file&#39;s schema</span>
    <span class="c1"># (all must be the same schema)</span>
    <span class="k">with</span> <span class="n">parquet</span><span class="o">.</span><span class="n">ParquetWriter</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">destination_path</span><span class="p">),</span> <span class="n">writer_schema</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">source_group</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">table</span> <span class="ow">in</span> <span class="p">[</span><span class="n">table</span> <span class="k">for</span> <span class="n">table</span> <span class="ow">in</span> <span class="n">source</span><span class="p">[</span><span class="s2">&quot;table&quot;</span><span class="p">]]:</span>
                <span class="c1"># if we haven&#39;t inferred the common schema</span>
                <span class="c1"># check that our file matches the expected schema, otherwise raise an error</span>
                <span class="k">if</span> <span class="n">common_schema</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">writer_schema</span><span class="o">.</span><span class="n">equals</span><span class="p">(</span>
                    <span class="n">parquet</span><span class="o">.</span><span class="n">read_schema</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
                <span class="p">):</span>
                    <span class="k">raise</span> <span class="n">SchemaException</span><span class="p">(</span>
                        <span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Detected mismatching schema for target concatenation group members:&quot;</span>
                            <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">source_group</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;table&#39;</span><span class="p">])</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">table</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>
                    <span class="p">)</span>

                <span class="c1"># read the file from the list and write to the concatted parquet file</span>
                <span class="c1"># note: we pass column order based on the first chunk file to help ensure schema</span>
                <span class="c1"># compatibility for the writer</span>
                <span class="n">writer</span><span class="o">.</span><span class="n">write_table</span><span class="p">(</span>
                    <span class="n">parquet</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span>
                        <span class="n">table</span><span class="p">,</span>
                        <span class="n">schema</span><span class="o">=</span><span class="n">writer_schema</span><span class="p">,</span>
                        <span class="n">memory_map</span><span class="o">=</span><span class="n">CYTOTABLE_ARROW_USE_MEMORY_MAPPING</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="c1"># remove the file which was written in the concatted parquet file (we no longer need it)</span>
                <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">table</span><span class="p">)</span><span class="o">.</span><span class="n">unlink</span><span class="p">()</span>

            <span class="c1"># attempt to clean up dir containing original table(s) only if it&#39;s empty</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="s2">&quot;table&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">parent</span><span class="p">)</span><span class="o">.</span><span class="n">rmdir</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">OSError</span> <span class="k">as</span> <span class="n">os_err</span><span class="p">:</span>
                <span class="c1"># raise only if we don&#39;t have a dir not empty errno</span>
                <span class="k">if</span> <span class="n">os_err</span><span class="o">.</span><span class="n">errno</span> <span class="o">!=</span> <span class="n">errno</span><span class="o">.</span><span class="n">ENOTEMPTY</span><span class="p">:</span>
                    <span class="k">raise</span>

    <span class="c1"># return the concatted parquet filename</span>
    <span class="n">concatted</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;table&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">destination_path</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">concatted</span>


<span class="nd">@python_app</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">_prepare_join_sql</span><span class="p">(</span>
    <span class="n">sources</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]],</span>
    <span class="n">joins</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Prepare join SQL statement with actual locations of data based on the sources.</span>

<span class="sd">    Args:</span>
<span class="sd">        sources: Dict[str, List[Dict[str, Any]]]:</span>
<span class="sd">            Grouped datasets of files which will be used by other functions.</span>
<span class="sd">            Includes the metadata concerning location of actual data.</span>
<span class="sd">        joins: str:</span>
<span class="sd">            DuckDB-compatible SQL which will be used to perform the join</span>
<span class="sd">            operations using the join_group keys as a reference.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str:</span>
<span class="sd">            String representing the SQL to be used in later join work.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">pathlib</span>

    <span class="c1"># replace with real location of sources for join sql</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">sources</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">stem</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">joins</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
            <span class="n">joins</span> <span class="o">=</span> <span class="n">joins</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">stem</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span><span class="si">}</span><span class="s2">.parquet&#39;&quot;</span><span class="p">,</span>
                <span class="nb">str</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">table</span><span class="p">)</span> <span class="k">for</span> <span class="n">table</span> <span class="ow">in</span> <span class="n">val</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;table&quot;</span><span class="p">]]),</span>
            <span class="p">)</span>

    <span class="k">return</span> <span class="n">joins</span>


<span class="nd">@python_app</span>
<span class="k">def</span> <span class="nf">_join_source_chunk</span><span class="p">(</span>
    <span class="n">dest_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">joins</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">chunk_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">drop_null</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Join sources based on join group keys (group of specific join column values)</span>

<span class="sd">    Args:</span>
<span class="sd">        dest_path: str:</span>
<span class="sd">            Destination path to write file-based content.</span>
<span class="sd">        joins: str:</span>
<span class="sd">            DuckDB-compatible SQL which will be used to perform the join</span>
<span class="sd">            operations using the join_group keys as a reference.</span>
<span class="sd">        join_group: List[Dict[str, Any]]:</span>
<span class="sd">            Group of joinable keys to be used as &quot;chunked&quot; filter</span>
<span class="sd">            of overall dataset.</span>
<span class="sd">        drop_null: bool:</span>
<span class="sd">            Whether to drop rows with null values within the resulting</span>
<span class="sd">            joined data.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str</span>
<span class="sd">            Path to joined file which is created as a result of this function.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">import</span> <span class="nn">pathlib</span>

    <span class="kn">import</span> <span class="nn">pyarrow.parquet</span> <span class="k">as</span> <span class="nn">parquet</span>

    <span class="kn">from</span> <span class="nn">cytotable.utils</span> <span class="kn">import</span> <span class="n">_duckdb_reader</span><span class="p">,</span> <span class="n">_write_parquet_table_with_metadata</span>

    <span class="c1"># Attempt to read the data to parquet file</span>
    <span class="c1"># using duckdb for extraction and pyarrow for</span>
    <span class="c1"># writing data to a parquet file.</span>
    <span class="c1"># read data with chunk size + offset</span>
    <span class="c1"># and export to parquet</span>
    <span class="k">with</span> <span class="n">_duckdb_reader</span><span class="p">()</span> <span class="k">as</span> <span class="n">ddb_reader</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">ddb_reader</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                </span><span class="si">{</span><span class="n">joins</span><span class="si">}</span>
<span class="s2">                LIMIT </span><span class="si">{</span><span class="n">chunk_size</span><span class="si">}</span><span class="s2"> OFFSET </span><span class="si">{</span><span class="n">offset</span><span class="si">}</span>
<span class="s2">                &quot;&quot;&quot;</span>
        <span class="p">)</span><span class="o">.</span><span class="n">arrow</span><span class="p">()</span>

    <span class="c1"># drop nulls if specified</span>
    <span class="k">if</span> <span class="n">drop_null</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">drop_null</span><span class="p">()</span>

    <span class="c1"># account for duplicate column names from joins</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># reversed order column check as col removals will change index order</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">colname</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">column_names</span><span class="p">))):</span>
        <span class="k">if</span> <span class="n">colname</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
            <span class="n">cols</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">colname</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">remove_column</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="c1"># inner sorted alphabetizes any columns which may not be part of custom_sort</span>
    <span class="c1"># outer sort provides pycytominer-specific column sort order</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">column_names</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="n">_column_sort</span><span class="p">))</span>

    <span class="n">result_file_path</span> <span class="o">=</span> <span class="p">(</span>
        <span class="c1"># store the result in the parent of the dest_path</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">dest_path</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span><span class="p">)</span><span class="si">}</span><span class="s2">/&quot;</span>
        <span class="c1"># use the dest_path stem in the name</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">dest_path</span><span class="p">)</span><span class="o">.</span><span class="n">stem</span><span class="p">)</span><span class="si">}</span><span class="s2">-&quot;</span>
        <span class="c1"># give the join chunk result a unique to arbitrarily</span>
        <span class="c1"># differentiate from other chunk groups which are mapped</span>
        <span class="c1"># and before they are brought together as one dataset</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">()</span><span class="o">.</span><span class="n">hex</span><span class="p">)</span><span class="si">}</span><span class="s2">.parquet&quot;</span>
    <span class="p">)</span>

    <span class="c1"># write the result</span>
    <span class="n">_write_parquet_table_with_metadata</span><span class="p">(</span>
        <span class="n">table</span><span class="o">=</span><span class="n">result</span><span class="p">,</span>
        <span class="n">where</span><span class="o">=</span><span class="n">result_file_path</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">result_file_path</span>


<span class="nd">@python_app</span>
<span class="k">def</span> <span class="nf">_concat_join_sources</span><span class="p">(</span>
    <span class="n">sources</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]],</span>
    <span class="n">dest_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">join_sources</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Concatenate join sources from parquet-based chunks.</span>

<span class="sd">    For a reference to data concatenation within Arrow see the following:</span>
<span class="sd">    https://arrow.apache.org/docs/python/generated/pyarrow.concat_tables.html</span>

<span class="sd">    Args:</span>
<span class="sd">        sources: Dict[str, List[Dict[str, Any]]]:</span>
<span class="sd">            Grouped datasets of files which will be used by other functions.</span>
<span class="sd">            Includes the metadata concerning location of actual data.</span>
<span class="sd">        dest_path: str:</span>
<span class="sd">            Destination path to write file-based content.</span>
<span class="sd">        join_sources: List[str]:</span>
<span class="sd">            List of local filepath destination for join source chunks</span>
<span class="sd">            which will be concatenated.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str</span>
<span class="sd">            Path to concatenated file which is created as a result of this function.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">import</span> <span class="nn">pathlib</span>
    <span class="kn">import</span> <span class="nn">shutil</span>

    <span class="kn">import</span> <span class="nn">pyarrow.parquet</span> <span class="k">as</span> <span class="nn">parquet</span>

    <span class="kn">from</span> <span class="nn">cytotable.constants</span> <span class="kn">import</span> <span class="p">(</span>
        <span class="n">CYTOTABLE_ARROW_USE_MEMORY_MAPPING</span><span class="p">,</span>
        <span class="n">CYTOTABLE_DEFAULT_PARQUET_METADATA</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="kn">from</span> <span class="nn">cytotable.utils</span> <span class="kn">import</span> <span class="n">_write_parquet_table_with_metadata</span>

    <span class="c1"># remove the unjoined concatted compartments to prepare final dest_path usage</span>
    <span class="c1"># (we now have joined results)</span>
    <span class="n">flattened_sources</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="nb">list</span><span class="p">(</span><span class="n">sources</span><span class="o">.</span><span class="n">values</span><span class="p">())))</span>
    <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">flattened_sources</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">table</span> <span class="ow">in</span> <span class="n">source</span><span class="p">[</span><span class="s2">&quot;table&quot;</span><span class="p">]:</span>
            <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">table</span><span class="p">)</span><span class="o">.</span><span class="n">unlink</span><span class="p">(</span><span class="n">missing_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># remove dir if we have it</span>
    <span class="k">if</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">dest_path</span><span class="p">)</span><span class="o">.</span><span class="n">is_dir</span><span class="p">():</span>
        <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">dest_path</span><span class="p">)</span>

    <span class="c1"># build a parquet file writer which will be used to append files</span>
    <span class="c1"># as a single concatted parquet file, referencing the first file&#39;s schema</span>
    <span class="c1"># (all must be the same schema)</span>
    <span class="n">writer_schema</span> <span class="o">=</span> <span class="n">parquet</span><span class="o">.</span><span class="n">read_schema</span><span class="p">(</span><span class="n">join_sources</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">with_metadata</span><span class="p">(</span>
        <span class="n">CYTOTABLE_DEFAULT_PARQUET_METADATA</span>
    <span class="p">)</span>
    <span class="k">with</span> <span class="n">parquet</span><span class="o">.</span><span class="n">ParquetWriter</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">dest_path</span><span class="p">),</span> <span class="n">writer_schema</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">table_path</span> <span class="ow">in</span> <span class="n">join_sources</span><span class="p">:</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">write_table</span><span class="p">(</span>
                <span class="n">parquet</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span>
                    <span class="n">table_path</span><span class="p">,</span>
                    <span class="n">schema</span><span class="o">=</span><span class="n">writer_schema</span><span class="p">,</span>
                    <span class="n">memory_map</span><span class="o">=</span><span class="n">CYTOTABLE_ARROW_USE_MEMORY_MAPPING</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="c1"># remove the file which was written in the concatted parquet file (we no longer need it)</span>
            <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">table_path</span><span class="p">)</span><span class="o">.</span><span class="n">unlink</span><span class="p">()</span>

    <span class="c1"># return modified sources format to indicate the final result</span>
    <span class="c1"># and retain the other source data for reference as needed</span>
    <span class="k">return</span> <span class="n">dest_path</span>


<span class="nd">@python_app</span>
<span class="k">def</span> <span class="nf">_infer_source_group_common_schema</span><span class="p">(</span>
    <span class="n">source_group</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="n">data_type_cast_map</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Infers a common schema for group of parquet files which may have</span>
<span class="sd">    similar but slightly different schema or data. Intended to assist with</span>
<span class="sd">    data concatenation and other operations.</span>

<span class="sd">    Args:</span>
<span class="sd">        source_group: List[Dict[str, Any]]:</span>
<span class="sd">            Group of one or more data sources which includes metadata about</span>
<span class="sd">            path to parquet data.</span>
<span class="sd">        data_type_cast_map: Optional[Dict[str, str]], default None</span>
<span class="sd">            A dictionary mapping data type groups to specific types.</span>
<span class="sd">            Roughly includes Arrow data types language from:</span>
<span class="sd">            https://arrow.apache.org/docs/python/api/datatypes.html</span>

<span class="sd">    Returns:</span>
<span class="sd">        List[Tuple[str, str]]</span>
<span class="sd">            A list of tuples which includes column name and PyArrow datatype.</span>
<span class="sd">            This data will later be used as the basis for forming a PyArrow schema.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">import</span> <span class="nn">pyarrow</span> <span class="k">as</span> <span class="nn">pa</span>
    <span class="kn">import</span> <span class="nn">pyarrow.parquet</span> <span class="k">as</span> <span class="nn">parquet</span>

    <span class="kn">from</span> <span class="nn">cytotable.exceptions</span> <span class="kn">import</span> <span class="n">SchemaException</span>

    <span class="c1"># read first file for basis of schema and column order for all others</span>
    <span class="n">common_schema</span> <span class="o">=</span> <span class="n">parquet</span><span class="o">.</span><span class="n">read_schema</span><span class="p">(</span><span class="n">source_group</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;table&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1"># infer common basis of schema and column order for all others</span>
    <span class="k">for</span> <span class="n">schema</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="n">parquet</span><span class="o">.</span><span class="n">read_schema</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">source_group</span>
        <span class="k">for</span> <span class="n">table</span> <span class="ow">in</span> <span class="n">source</span><span class="p">[</span><span class="s2">&quot;table&quot;</span><span class="p">]</span>
    <span class="p">]:</span>
        <span class="c1"># account for completely equal schema</span>
        <span class="k">if</span> <span class="n">schema</span><span class="o">.</span><span class="n">equals</span><span class="p">(</span><span class="n">common_schema</span><span class="p">):</span>
            <span class="k">continue</span>

        <span class="c1"># gather field names from schema</span>
        <span class="n">schema_field_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">schema</span><span class="p">]</span>

        <span class="c1"># reversed enumeration because removing indexes ascendingly changes schema field order</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">field</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">common_schema</span><span class="p">))):</span>
            <span class="c1"># check whether field name is contained within writer basis, remove if not</span>
            <span class="c1"># note: because this only checks for naming, we defer to initially detected type</span>
            <span class="k">if</span> <span class="n">field</span><span class="o">.</span><span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">schema_field_names</span><span class="p">:</span>
                <span class="n">common_schema</span> <span class="o">=</span> <span class="n">common_schema</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

            <span class="c1"># check if we have a nulltype and non-nulltype conflict, deferring to non-nulltype</span>
            <span class="k">elif</span> <span class="n">pa</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">is_null</span><span class="p">(</span><span class="n">field</span><span class="o">.</span><span class="n">type</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">pa</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">is_null</span><span class="p">(</span>
                <span class="n">schema</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">field</span><span class="o">.</span><span class="n">name</span><span class="p">)</span><span class="o">.</span><span class="n">type</span>
            <span class="p">):</span>
                <span class="n">common_schema</span> <span class="o">=</span> <span class="n">common_schema</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                    <span class="n">index</span><span class="p">,</span> <span class="n">field</span><span class="o">.</span><span class="n">with_type</span><span class="p">(</span><span class="n">schema</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">field</span><span class="o">.</span><span class="n">name</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
                <span class="p">)</span>

            <span class="c1"># check if we have an integer to float challenge and enable later casting</span>
            <span class="k">elif</span> <span class="n">pa</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">is_integer</span><span class="p">(</span><span class="n">field</span><span class="o">.</span><span class="n">type</span><span class="p">)</span> <span class="ow">and</span> <span class="n">pa</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">is_floating</span><span class="p">(</span>
                <span class="n">schema</span><span class="o">.</span><span class="n">field</span><span class="p">(</span><span class="n">field</span><span class="o">.</span><span class="n">name</span><span class="p">)</span><span class="o">.</span><span class="n">type</span>
            <span class="p">):</span>
                <span class="n">common_schema</span> <span class="o">=</span> <span class="n">common_schema</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
                    <span class="n">index</span><span class="p">,</span>
                    <span class="n">field</span><span class="o">.</span><span class="n">with_type</span><span class="p">(</span>
                        <span class="c1"># use float64 as a default here if we aren&#39;t casting floats</span>
                        <span class="n">pa</span><span class="o">.</span><span class="n">float64</span><span class="p">()</span>
                        <span class="k">if</span> <span class="n">data_type_cast_map</span> <span class="ow">is</span> <span class="kc">None</span>
                        <span class="ow">or</span> <span class="s2">&quot;float&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data_type_cast_map</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                        <span class="c1"># otherwise use the float data type cast type</span>
                        <span class="k">else</span> <span class="n">pa</span><span class="o">.</span><span class="n">type_for_alias</span><span class="p">(</span><span class="n">data_type_cast_map</span><span class="p">[</span><span class="s2">&quot;float&quot;</span><span class="p">])</span>
                    <span class="p">),</span>
                <span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">common_schema</span><span class="o">.</span><span class="n">names</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">SchemaException</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="s2">&quot;No common schema basis to perform concatenation for source group.&quot;</span>
                <span class="s2">&quot; All columns mismatch one another within the group.&quot;</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># return a python-native list of tuples with column names and str types</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span>
        <span class="nb">zip</span><span class="p">(</span>
            <span class="n">common_schema</span><span class="o">.</span><span class="n">names</span><span class="p">,</span>
            <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">schema_type</span><span class="p">)</span> <span class="k">for</span> <span class="n">schema_type</span> <span class="ow">in</span> <span class="n">common_schema</span><span class="o">.</span><span class="n">types</span><span class="p">],</span>
        <span class="p">)</span>
    <span class="p">)</span>


<span class="nd">@python_app</span>
<span class="k">def</span> <span class="nf">_return_future</span><span class="p">(</span><span class="nb">input</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is a simple wrapper python_app to allow</span>
<span class="sd">    the return of join_app-compliant output (must be a Parsl future)</span>

<span class="sd">    Args:</span>
<span class="sd">        input: Any</span>
<span class="sd">            Any input which will be used within the context of a</span>
<span class="sd">            Parsl join_app future return.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Any</span>
<span class="sd">            Returns the input as provided wrapped within the context</span>
<span class="sd">            of a python_app for the purpose of a join_app.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="nb">input</span>


<span class="nd">@join_app</span>
<span class="k">def</span> <span class="nf">_to_parquet</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments, too-many-locals</span>
    <span class="n">source_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">dest_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">source_datatype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">metadata</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]],</span>
    <span class="n">compartments</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]],</span>
    <span class="n">identifying_columns</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]],</span>
    <span class="n">concat</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">join</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">joins</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">chunk_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">infer_common_schema</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">drop_null</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">data_type_cast_map</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]],</span> <span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Export data to parquet.</span>

<span class="sd">    Args:</span>
<span class="sd">        source_path: str:</span>
<span class="sd">            str reference to read source files from.</span>
<span class="sd">            Note: may be local or remote object-storage</span>
<span class="sd">            location using convention &quot;s3://...&quot; or similar.</span>
<span class="sd">        dest_path: str:</span>
<span class="sd">            Path to write files to. This path will be used for</span>
<span class="sd">            intermediary data work and must be a new file or directory path.</span>
<span class="sd">            This parameter will result in a directory on `join=False`.</span>
<span class="sd">            This parameter will result in a single file on `join=True`.</span>
<span class="sd">            Note: this may only be a local path.</span>
<span class="sd">        source_datatype: Optional[str]: (Default value = None)</span>
<span class="sd">            Source datatype to focus on during conversion.</span>
<span class="sd">        metadata: Union[List[str], Tuple[str, ...]]:</span>
<span class="sd">            Metadata names to use for conversion.</span>
<span class="sd">        compartments: Union[List[str], Tuple[str, ...]]: (Default value = None)</span>
<span class="sd">            Compartment names to use for conversion.</span>
<span class="sd">        identifying_columns: Union[List[str], Tuple[str, ...]]:</span>
<span class="sd">            Column names which are used as ID&#39;s and as a result need to be</span>
<span class="sd">            ignored with regards to renaming.</span>
<span class="sd">        concat: bool:</span>
<span class="sd">            Whether to concatenate similar files together.</span>
<span class="sd">        join: bool:</span>
<span class="sd">            Whether to join the compartment data together into one dataset.</span>
<span class="sd">        joins: str:</span>
<span class="sd">            DuckDB-compatible SQL which will be used to perform the join operations.</span>
<span class="sd">        chunk_size: Optional[int],</span>
<span class="sd">            Size of join chunks which is used to limit data size during join ops.</span>
<span class="sd">        infer_common_schema: bool:  (Default value = True)</span>
<span class="sd">            Whether to infer a common schema when concatenating sources.</span>
<span class="sd">        drop_null: bool:</span>
<span class="sd">            Whether to drop null results.</span>
<span class="sd">        data_type_cast_map: Dict[str, str]</span>
<span class="sd">            A dictionary mapping data type groups to specific types.</span>
<span class="sd">            Roughly includes Arrow data types language from:</span>
<span class="sd">            https://arrow.apache.org/docs/python/api/datatypes.html</span>
<span class="sd">        **kwargs: Any:</span>
<span class="sd">            Keyword args used for gathering source data, primarily relevant for</span>
<span class="sd">            Cloudpathlib cloud-based client configuration.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[Dict[str, List[Dict[str, Any]]], str]:</span>
<span class="sd">            Grouped sources which include metadata about destination filepath</span>
<span class="sd">            where parquet file was written or a string filepath for the joined</span>
<span class="sd">            result.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">from</span> <span class="nn">cytotable.convert</span> <span class="kn">import</span> <span class="p">(</span>
        <span class="n">_concat_join_sources</span><span class="p">,</span>
        <span class="n">_concat_source_group</span><span class="p">,</span>
        <span class="n">_get_table_chunk_offsets</span><span class="p">,</span>
        <span class="n">_infer_source_group_common_schema</span><span class="p">,</span>
        <span class="n">_join_source_chunk</span><span class="p">,</span>
        <span class="n">_prepend_column_name</span><span class="p">,</span>
        <span class="n">_return_future</span><span class="p">,</span>
        <span class="n">_source_chunk_to_parquet</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="kn">from</span> <span class="nn">cytotable.sources</span> <span class="kn">import</span> <span class="n">_gather_sources</span>
    <span class="kn">from</span> <span class="nn">cytotable.utils</span> <span class="kn">import</span> <span class="n">_expand_path</span>

    <span class="c1"># gather sources to be processed</span>
    <span class="n">sources</span> <span class="o">=</span> <span class="n">_gather_sources</span><span class="p">(</span>
        <span class="n">source_path</span><span class="o">=</span><span class="n">source_path</span><span class="p">,</span>
        <span class="n">source_datatype</span><span class="o">=</span><span class="n">source_datatype</span><span class="p">,</span>
        <span class="n">targets</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">metadata</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">compartments</span><span class="p">),</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>

    <span class="c1"># expand the destination path</span>
    <span class="n">expanded_dest_path</span> <span class="o">=</span> <span class="n">_expand_path</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">dest_path</span><span class="p">)</span>

    <span class="c1"># prepare offsets for chunked data export from source tables</span>
    <span class="n">offsets_prepared</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">source_group_name</span><span class="p">:</span> <span class="p">[</span>
            <span class="nb">dict</span><span class="p">(</span>
                <span class="n">source</span><span class="p">,</span>
                <span class="o">**</span><span class="p">{</span>
                    <span class="s2">&quot;offsets&quot;</span><span class="p">:</span> <span class="n">_get_table_chunk_offsets</span><span class="p">(</span>
                        <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">,</span>
                        <span class="n">chunk_size</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">,</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
                <span class="p">},</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">source_group_vals</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">source_group_name</span><span class="p">,</span> <span class="n">source_group_vals</span> <span class="ow">in</span> <span class="n">sources</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    <span class="p">}</span>

    <span class="c1"># if offsets is none and we haven&#39;t halted, remove the file as there</span>
    <span class="c1"># were input formatting errors which will create challenges downstream</span>
    <span class="n">invalid_files_dropped</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">source_group_name</span><span class="p">:</span> <span class="p">[</span>
            <span class="c1"># ensure we have offsets</span>
            <span class="n">source</span>
            <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">source_group_vals</span>
            <span class="k">if</span> <span class="n">source</span><span class="p">[</span><span class="s2">&quot;offsets&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">source_group_name</span><span class="p">,</span> <span class="n">source_group_vals</span> <span class="ow">in</span> <span class="n">offsets_prepared</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="c1"># ensure we have source_groups with at least one source table</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_group_vals</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="p">}</span>

    <span class="c1"># gather column names and types from source tables</span>
    <span class="n">column_names_and_types_gathered</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">source_group_name</span><span class="p">:</span> <span class="p">[</span>
            <span class="nb">dict</span><span class="p">(</span>
                <span class="n">source</span><span class="p">,</span>
                <span class="o">**</span><span class="p">{</span>
                    <span class="s2">&quot;columns&quot;</span><span class="p">:</span> <span class="n">_prep_cast_column_data_types</span><span class="p">(</span>
                        <span class="n">columns</span><span class="o">=</span><span class="n">_get_table_columns_and_types</span><span class="p">(</span>
                            <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="n">data_type_cast_map</span><span class="o">=</span><span class="n">data_type_cast_map</span><span class="p">,</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
                <span class="p">},</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">source_group_vals</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">source_group_name</span><span class="p">,</span> <span class="n">source_group_vals</span> <span class="ow">in</span> <span class="n">invalid_files_dropped</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    <span class="p">}</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">source_group_name</span><span class="p">:</span> <span class="p">[</span>
            <span class="nb">dict</span><span class="p">(</span>
                <span class="n">source</span><span class="p">,</span>
                <span class="o">**</span><span class="p">{</span>
                    <span class="s2">&quot;table&quot;</span><span class="p">:</span> <span class="p">[</span>
                        <span class="c1"># perform column renaming and create potential return result</span>
                        <span class="n">_prepend_column_name</span><span class="p">(</span>
                            <span class="c1"># perform chunked data export to parquet using offsets</span>
                            <span class="n">table_path</span><span class="o">=</span><span class="n">_source_chunk_to_parquet</span><span class="p">(</span>
                                <span class="n">source_group_name</span><span class="o">=</span><span class="n">source_group_name</span><span class="p">,</span>
                                <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">,</span>
                                <span class="n">chunk_size</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">,</span>
                                <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
                                <span class="n">dest_path</span><span class="o">=</span><span class="n">expanded_dest_path</span><span class="p">,</span>
                            <span class="p">),</span>
                            <span class="n">source_group_name</span><span class="o">=</span><span class="n">source_group_name</span><span class="p">,</span>
                            <span class="n">identifying_columns</span><span class="o">=</span><span class="n">identifying_columns</span><span class="p">,</span>
                            <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
                            <span class="n">compartments</span><span class="o">=</span><span class="n">compartments</span><span class="p">,</span>
                        <span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
                        <span class="k">for</span> <span class="n">offset</span> <span class="ow">in</span> <span class="n">source</span><span class="p">[</span><span class="s2">&quot;offsets&quot;</span><span class="p">]</span>
                    <span class="p">]</span>
                <span class="p">},</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">source_group_vals</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">source_group_name</span><span class="p">,</span> <span class="n">source_group_vals</span> <span class="ow">in</span> <span class="n">column_names_and_types_gathered</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    <span class="p">}</span>

    <span class="c1"># if we&#39;re concatting or joining and need to infer the common schema</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">concat</span> <span class="ow">or</span> <span class="n">join</span><span class="p">)</span> <span class="ow">and</span> <span class="n">infer_common_schema</span><span class="p">:</span>
        <span class="c1"># create a common schema for concatenation work</span>
        <span class="n">common_schema_determined</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">source_group_name</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;sources&quot;</span><span class="p">:</span> <span class="n">source_group_vals</span><span class="p">,</span>
                <span class="s2">&quot;common_schema&quot;</span><span class="p">:</span> <span class="n">_infer_source_group_common_schema</span><span class="p">(</span>
                    <span class="n">source_group</span><span class="o">=</span><span class="n">source_group_vals</span><span class="p">,</span>
                    <span class="n">data_type_cast_map</span><span class="o">=</span><span class="n">data_type_cast_map</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">source_group_name</span><span class="p">,</span> <span class="n">source_group_vals</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>

    <span class="c1"># if concat or join, concat the source groups</span>
    <span class="c1"># note: join implies a concat, but concat does not imply a join</span>
    <span class="c1"># We concat to join in order to create a common schema for join work</span>
    <span class="c1"># performed after concatenation.</span>
    <span class="k">if</span> <span class="n">concat</span> <span class="ow">or</span> <span class="n">join</span><span class="p">:</span>
        <span class="c1"># create a potential return result for concatenation output</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">source_group_name</span><span class="p">:</span> <span class="n">_concat_source_group</span><span class="p">(</span>
                <span class="n">source_group_name</span><span class="o">=</span><span class="n">source_group_name</span><span class="p">,</span>
                <span class="n">source_group</span><span class="o">=</span><span class="n">source_group_vals</span><span class="p">[</span><span class="s2">&quot;sources&quot;</span><span class="p">],</span>
                <span class="n">dest_path</span><span class="o">=</span><span class="n">expanded_dest_path</span><span class="p">,</span>
                <span class="n">common_schema</span><span class="o">=</span><span class="n">source_group_vals</span><span class="p">[</span><span class="s2">&quot;common_schema&quot;</span><span class="p">],</span>
            <span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">source_group_name</span><span class="p">,</span> <span class="n">source_group_vals</span> <span class="ow">in</span> <span class="n">common_schema_determined</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>

    <span class="c1"># conditional section for merging</span>
    <span class="c1"># note: join implies a concat, but concat does not imply a join</span>
    <span class="k">if</span> <span class="n">join</span><span class="p">:</span>
        <span class="n">prepared_joins_sql</span> <span class="o">=</span> <span class="n">_prepare_join_sql</span><span class="p">(</span><span class="n">sources</span><span class="o">=</span><span class="n">results</span><span class="p">,</span> <span class="n">joins</span><span class="o">=</span><span class="n">joins</span><span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>

        <span class="c1"># map joined results based on the join groups gathered above</span>
        <span class="c1"># note: after mapping we end up with a list of strings (task returns str)</span>
        <span class="n">join_sources_result</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">_join_source_chunk</span><span class="p">(</span>
                <span class="c1"># gather the result of concatted sources prior to</span>
                <span class="c1"># join group merging as each mapped task run will need</span>
                <span class="c1"># full concat results</span>
                <span class="n">dest_path</span><span class="o">=</span><span class="n">expanded_dest_path</span><span class="p">,</span>
                <span class="n">joins</span><span class="o">=</span><span class="n">prepared_joins_sql</span><span class="p">,</span>
                <span class="n">chunk_size</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">,</span>
                <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
                <span class="n">drop_null</span><span class="o">=</span><span class="n">drop_null</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
            <span class="c1"># create join group for querying the concatenated</span>
            <span class="c1"># data in order to perform memory-safe joining</span>
            <span class="c1"># per user chunk size specification.</span>
            <span class="k">for</span> <span class="n">offset</span> <span class="ow">in</span> <span class="n">_get_table_chunk_offsets</span><span class="p">(</span>
                <span class="n">sql_stmt</span><span class="o">=</span><span class="n">prepared_joins_sql</span><span class="p">,</span>
                <span class="n">chunk_size</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>
        <span class="p">]</span>

        <span class="c1"># concat our join chunks together as one cohesive dataset</span>
        <span class="c1"># return results in common format which includes metadata</span>
        <span class="c1"># for lineage and debugging</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">_concat_join_sources</span><span class="p">(</span>
            <span class="n">dest_path</span><span class="o">=</span><span class="n">expanded_dest_path</span><span class="p">,</span>
            <span class="n">join_sources</span><span class="o">=</span><span class="n">join_sources_result</span><span class="p">,</span>
            <span class="n">sources</span><span class="o">=</span><span class="n">results</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>

    <span class="c1"># wrap the final result as a future and return</span>
    <span class="k">return</span> <span class="n">_return_future</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>


<div class="viewcode-block" id="convert"><a class="viewcode-back" href="../../python-api.html#cytotable.convert.convert">[docs]</a><span class="k">def</span> <span class="nf">convert</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments,too-many-locals</span>
    <span class="n">source_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">dest_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">dest_datatype</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;parquet&quot;</span><span class="p">],</span>
    <span class="n">source_datatype</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">compartments</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">identifying_columns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">concat</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">join</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">joins</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">chunk_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">infer_common_schema</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">drop_null</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">data_type_cast_map</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">preset</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;cellprofiler_csv&quot;</span><span class="p">,</span>
    <span class="n">parsl_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">parsl</span><span class="o">.</span><span class="n">Config</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]],</span> <span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert file-based data from various sources to Pycytominer-compatible standards.</span>

<span class="sd">    Note: source paths may be local or remote object-storage location</span>
<span class="sd">    using convention &quot;s3://...&quot; or similar.</span>

<span class="sd">    Args:</span>
<span class="sd">        source_path: str:</span>
<span class="sd">            str reference to read source files from.</span>
<span class="sd">            Note: may be local or remote object-storage location</span>
<span class="sd">            using convention &quot;s3://...&quot; or similar.</span>
<span class="sd">        dest_path: str:</span>
<span class="sd">            Path to write files to. This path will be used for</span>
<span class="sd">            intermediary data work and must be a new file or directory path.</span>
<span class="sd">            This parameter will result in a directory on `join=False`.</span>
<span class="sd">            This parameter will result in a single file on `join=True`.</span>
<span class="sd">            Note: this may only be a local path.</span>
<span class="sd">        dest_datatype: Literal[&quot;parquet&quot;]:</span>
<span class="sd">            Destination datatype to write to.</span>
<span class="sd">        source_datatype: Optional[str]:  (Default value = None)</span>
<span class="sd">            Source datatype to focus on during conversion.</span>
<span class="sd">        metadata: Union[List[str], Tuple[str, ...]]:</span>
<span class="sd">            Metadata names to use for conversion.</span>
<span class="sd">        compartments: Union[List[str], Tuple[str, str, str, str]]:</span>
<span class="sd">            (Default value = None)</span>
<span class="sd">            Compartment names to use for conversion.</span>
<span class="sd">        identifying_columns: Union[List[str], Tuple[str, ...]]:</span>
<span class="sd">            Column names which are used as ID&#39;s and as a result need to be</span>
<span class="sd">            ignored with regards to renaming.</span>
<span class="sd">        concat: bool:  (Default value = True)</span>
<span class="sd">            Whether to concatenate similar files together.</span>
<span class="sd">        join: bool:  (Default value = True)</span>
<span class="sd">            Whether to join the compartment data together into one dataset</span>
<span class="sd">        joins: str: (Default value = None):</span>
<span class="sd">            DuckDB-compatible SQL which will be used to perform the join operations.</span>
<span class="sd">        chunk_size: Optional[int] (Default value = None)</span>
<span class="sd">            Size of join chunks which is used to limit data size during join ops</span>
<span class="sd">        infer_common_schema: bool: (Default value = True)</span>
<span class="sd">            Whether to infer a common schema when concatenating sources.</span>
<span class="sd">        drop_null: bool (Default value = False)</span>
<span class="sd">            Whether to drop nan/null values from results</span>
<span class="sd">        preset: str (Default value = &quot;cellprofiler_csv&quot;)</span>
<span class="sd">            an optional group of presets to use based on common configurations</span>
<span class="sd">        parsl_config: Optional[parsl.Config] (Default value = None)</span>
<span class="sd">            Optional Parsl configuration to use for running CytoTable operations.</span>
<span class="sd">            Note: when using CytoTable multiple times in the same process,</span>
<span class="sd">            CytoTable will use the first provided configuration for all runs.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[Dict[str, List[Dict[str, Any]]], str]</span>
<span class="sd">            Grouped sources which include metadata about destination filepath</span>
<span class="sd">            where parquet file was written or str of joined result filepath.</span>

<span class="sd">    Example:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from cytotable import convert</span>

<span class="sd">            # using a local path with cellprofiler csv presets</span>
<span class="sd">            convert(</span>
<span class="sd">                source_path=&quot;./tests/data/cellprofiler/ExampleHuman&quot;,</span>
<span class="sd">                source_datatype=&quot;csv&quot;,</span>
<span class="sd">                dest_path=&quot;ExampleHuman.parquet&quot;,</span>
<span class="sd">                dest_datatype=&quot;parquet&quot;,</span>
<span class="sd">                preset=&quot;cellprofiler_csv&quot;,</span>
<span class="sd">            )</span>

<span class="sd">            # using an s3-compatible path with no signature for client</span>
<span class="sd">            # and cellprofiler csv presets</span>
<span class="sd">            convert(</span>
<span class="sd">                source_path=&quot;s3://s3path&quot;,</span>
<span class="sd">                source_datatype=&quot;csv&quot;,</span>
<span class="sd">                dest_path=&quot;s3_local_result&quot;,</span>
<span class="sd">                dest_datatype=&quot;parquet&quot;,</span>
<span class="sd">                concat=True,</span>
<span class="sd">                preset=&quot;cellprofiler_csv&quot;,</span>
<span class="sd">                no_sign_request=True,</span>
<span class="sd">            )</span>

<span class="sd">            # using local path with cellprofiler sqlite presets</span>
<span class="sd">            convert(</span>
<span class="sd">                source_path=&quot;example.sqlite&quot;,</span>
<span class="sd">                dest_path=&quot;example.parquet&quot;,</span>
<span class="sd">                dest_datatype=&quot;parquet&quot;,</span>
<span class="sd">                preset=&quot;cellprofiler_sqlite&quot;,</span>
<span class="sd">            )</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Raise an exception if an existing path is provided as the destination</span>
    <span class="c1"># to avoid removing existing data or unrelated data removal.</span>
    <span class="k">if</span> <span class="n">_expand_path</span><span class="p">(</span><span class="n">dest_path</span><span class="p">)</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
        <span class="k">raise</span> <span class="n">CytoTableException</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="s2">&quot;An existing file or directory was provided as dest_path: &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="n">dest_path</span><span class="si">}</span><span class="s2">&#39;. Please use a new path for this parameter.&quot;</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># attempt to load parsl configuration if we didn&#39;t already load one</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_parsl_loaded</span><span class="p">():</span>
        <span class="c1"># if we don&#39;t have a parsl configuration provided, load the default</span>
        <span class="k">if</span> <span class="n">parsl_config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">parsl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">_default_parsl_config</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># else we attempt to load the given parsl configuration</span>
            <span class="n">parsl</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">parsl_config</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># otherwise warn the user about previous config.</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Reusing previously loaded Parsl configuration.&quot;</span><span class="p">)</span>

    <span class="c1"># optionally load preset configuration for arguments</span>
    <span class="c1"># note: defer to overrides from parameters whose values</span>
    <span class="c1"># are not None (allows intermixing of presets and overrides)</span>
    <span class="k">if</span> <span class="n">preset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">metadata</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">cast</span><span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="n">preset</span><span class="p">][</span><span class="s2">&quot;CONFIG_NAMES_METADATA&quot;</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">metadata</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">metadata</span>
        <span class="p">)</span>
        <span class="n">compartments</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">cast</span><span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="n">preset</span><span class="p">][</span><span class="s2">&quot;CONFIG_NAMES_COMPARTMENTS&quot;</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">compartments</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">compartments</span>
        <span class="p">)</span>
        <span class="n">identifying_columns</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">cast</span><span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="n">preset</span><span class="p">][</span><span class="s2">&quot;CONFIG_IDENTIFYING_COLUMNS&quot;</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">identifying_columns</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">identifying_columns</span>
        <span class="p">)</span>
        <span class="n">joins</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="n">preset</span><span class="p">][</span><span class="s2">&quot;CONFIG_JOINS&quot;</span><span class="p">])</span> <span class="k">if</span> <span class="n">joins</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">joins</span>
        <span class="n">chunk_size</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">cast</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="n">preset</span><span class="p">][</span><span class="s2">&quot;CONFIG_CHUNK_SIZE&quot;</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">chunk_size</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">chunk_size</span>
        <span class="p">)</span>

    <span class="c1"># send sources to be written to parquet if selected</span>
    <span class="k">if</span> <span class="n">dest_datatype</span> <span class="o">==</span> <span class="s2">&quot;parquet&quot;</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">_to_parquet</span><span class="p">(</span>
            <span class="n">source_path</span><span class="o">=</span><span class="n">source_path</span><span class="p">,</span>
            <span class="n">dest_path</span><span class="o">=</span><span class="n">dest_path</span><span class="p">,</span>
            <span class="n">source_datatype</span><span class="o">=</span><span class="n">source_datatype</span><span class="p">,</span>
            <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
            <span class="n">compartments</span><span class="o">=</span><span class="n">compartments</span><span class="p">,</span>
            <span class="n">identifying_columns</span><span class="o">=</span><span class="n">identifying_columns</span><span class="p">,</span>
            <span class="n">concat</span><span class="o">=</span><span class="n">concat</span><span class="p">,</span>
            <span class="n">join</span><span class="o">=</span><span class="n">join</span><span class="p">,</span>
            <span class="n">joins</span><span class="o">=</span><span class="n">joins</span><span class="p">,</span>
            <span class="n">chunk_size</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">,</span>
            <span class="n">infer_common_schema</span><span class="o">=</span><span class="n">infer_common_schema</span><span class="p">,</span>
            <span class="n">drop_null</span><span class="o">=</span><span class="n">drop_null</span><span class="p">,</span>
            <span class="n">data_type_cast_map</span><span class="o">=</span><span class="n">data_type_cast_map</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">output</span></div>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">CytoTable</a></h1>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=cytomining&repo=CytoTable&type=star&count=false&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../code_of_conduct.html">Code of Conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../architecture.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python-api.html">Python API</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2022, Cytomining Community.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 6.2.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
    </div>

    

    
  </body>
</html>